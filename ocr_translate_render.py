import os
import glob
import json
import cv2
import numpy as np
import math
import time
from multiprocessing import Process, set_start_method
# L∆∞u √Ω: Kh√¥ng import paddle ho·∫∑c kh·ªüi t·∫°o OCR ·ªü global scope ƒë·ªÉ tr√°nh xung ƒë·ªôt CUDA

from PIL import Image, ImageDraw, ImageFont
from deep_translator import GoogleTranslator

# ================= C·∫§U H√åNH PH·∫¶N C·ª®NG =================
NUM_GPUS = 4           # S·ªë l∆∞·ª£ng GPU
BATCH_SIZE_OCR = 16    # S·ªë ·∫£nh x·ª≠ l√Ω trong 1 l·∫ßn load v√†o RAM (Batch logic c·ªßa code)

# ================= C·∫§U H√åNH TH∆Ø M·ª§C =================
RAW_DIR = "./frames_raw"         
JSON_DIR = "./json_cache"        
TRANSLATED_DIR = "./frames_done" 
FONT_PATH = "arial.ttf"          

LANG_SOURCE = 'de' 
LANG_TARGET = 'en'
BATCH_SIZE_TRANS = 50 

# Kh·ªüi t·∫°o Translator (Global OK v√¨ n√≥ d√πng CPU/API request)
try:
    translator = GoogleTranslator(source=LANG_SOURCE, target=LANG_TARGET)
except:
    pass # X·ª≠ l√Ω sau trong h√†m d·ªãch

# ==========================================================
#  C√ÅC H√ÄM V·∫º (Gi·ªØ nguy√™n logic c·ªßa b·∫°n)
# ==========================================================
def wrap_text_by_width(draw, text, font, max_width):
    words = text.split()
    lines = []
    line = ""
    for word in words:
        test_line = (line + " " + word).strip()
        bbox = draw.textbbox((0, 0), test_line, font=font)
        w = bbox[2] - bbox[0]
        if w <= max_width:
            line = test_line
        else:
            if line: lines.append(line)
            line = word
    if line: lines.append(line)
    return lines

def get_optimal_font_and_lines(draw, text, font_path, box_width, box_height, padding=4):
    max_size = min(int(box_height), 120)
    min_size = 10
    if not os.path.exists(font_path):
        font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"
    safe_width = box_width - (padding * 2)
    safe_height = box_height - (padding * 2)
    spacing = 4 
    default_font = ImageFont.load_default()

    for size in range(max_size, min_size, -2):
        if size <= 0: break
        try:
            font = ImageFont.truetype(font_path, size)
        except:
            font = default_font
            break
        lines = wrap_text_by_width(draw, text, font, safe_width)
        bbox_sample = draw.textbbox((0, 0), "Ay", font=font)
        line_height = bbox_sample[3] - bbox_sample[1]
        total_text_height = (len(lines) * line_height) + ((len(lines) - 1) * spacing)
        if total_text_height <= safe_height:
            return font, lines, total_text_height, line_height

    try: font = ImageFont.truetype(font_path, min_size)
    except: font = default_font
    lines = wrap_text_by_width(draw, text, font, safe_width)
    return font, lines, safe_height, 12

def render_text_in_box(draw, translated, font_path, x_min, y_min, x_max, y_max):
    box_width = x_max - x_min
    box_height = y_max - y_min
    if box_width < 10 or box_height < 10: return
    font, lines, text_block_height, line_height = get_optimal_font_and_lines(
        draw, translated, font_path, box_width, box_height
    )
    draw.rectangle([(x_min, y_min), (x_max, y_max)], fill="white")
    start_y = y_min + (box_height - text_block_height) // 2
    if start_y < y_min: start_y = y_min + 2
    current_y = start_y
    spacing = 4
    for line in lines:
        bbox = draw.textbbox((0, 0), line, font=font)
        line_w = bbox[2] - bbox[0]
        start_x = x_min + (box_width - line_w) // 2
        draw.text((start_x, current_y), line, fill="black", font=font)
        current_y += line_height + spacing

# ================= H√ÄM X·ª¨ L√ù C·ª¶A T·ª™NG WORKER (GPU) =================
def worker_ocr_process(gpu_id, image_files):
    """
    Worker x·ª≠ l√Ω OCR tr√™n GPU
    """
    # 1. QUAN TR·ªåNG: Set bi·∫øn m√¥i tr∆∞·ªùng TR∆Ø·ªöC KHI import paddle
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
    
    # 2. Import Paddle b√™n trong worker (ƒë·ªÉ tr√°nh xung ƒë·ªôt context v·ªõi main)
    import paddle
    from paddleocr import PaddleOCR

    # 3. Set device c·ª• th·ªÉ cho process n√†y
    # L∆∞u √Ω: Khi ƒë√£ set CUDA_VISIBLE_DEVICES="2" th√¨ process ch·ªâ nh√¨n th·∫•y 1 GPU
    # v√† n√≥ ƒë∆∞·ª£c ƒë√°nh s·ªë l√† 0. V√¨ v·∫≠y lu√¥n set l√† 'gpu:0'
    paddle.device.set_device('gpu:0')

    print(f"üöÄ Worker GPU {gpu_id} (PID {os.getpid()}) kh·ªüi ƒë·ªông...")
    
    try:
        # 4. Kh·ªüi t·∫°o Engine v·ªõi tham s·ªë use_gpu=True
        # gpu_mem=500: D√†nh ra 500MB VRAM kh·ªüi t·∫°o, tr√°nh chi·∫øm h·∫øt ngay l·∫≠p t·ª©c
        ocr_engine = PaddleOCR(
            lang='german', 
            use_angle_cls=False, 
            # use_gpu=True,            # <--- B·∫ÆT BU·ªòC
        )
    except Exception as e:
        print(f"‚ùå GPU {gpu_id} l·ªói Init: {e}")
        return

    total_files = len(image_files)
    processed_count = 0
    
    # Loop x·ª≠ l√Ω batch
    for i in range(0, total_files, BATCH_SIZE_OCR):
        batch_items = image_files[i : i + BATCH_SIZE_OCR]
        loaded_images = [] 
        
        # Load ·∫£nh
        for img_path, json_path, filename in batch_items:
            try:
                img = cv2.imread(img_path)
                if img is not None:
                    loaded_images.append((img, json_path, filename))
            except:
                pass
        
        if not loaded_images: continue

        # OCR t·ª´ng ·∫£nh
        for img, json_out_path, fname in loaded_images:
            try:
                result = ocr_engine.predict(img)
                ocr_data = []

                # --- SAFE PARSING ---
                if result and isinstance(result, list) and result[0]:
                    for line in result[0]:
                        try:
                            box = line[0]
                            content = line[1]
                            # content structure: ('text', score)
                            text = content[0]
                            score = content[1]

                            if score > 0.6: # TƒÉng ng∆∞·ª°ng t·ª± tin l√™n 0.6 cho s·∫°ch
                                xs = [pt[0] for pt in box]
                                ys = [pt[1] for pt in box]
                                
                                ocr_data.append({
                                    "box": [int(min(xs)), int(min(ys)), int(max(xs)), int(max(ys))],
                                    "text": str(text),
                                    "confidence": float(score),
                                    "translated": ""
                                })
                        except:
                            continue
                
                with open(json_out_path, 'w', encoding='utf-8') as f:
                    json.dump({"frame": fname, "texts": ocr_data}, f, ensure_ascii=False, indent=2)

            except Exception as e:
                print(f"‚ùå L·ªói {fname} tr√™n GPU {gpu_id}: {e}")

        # C·∫≠p nh·∫≠t ti·∫øn ƒë·ªô
        processed_count += len(loaded_images)
        if i % (BATCH_SIZE_OCR * 2) == 0:
            # In ra log c√≥ k√®m GPU ID ƒë·ªÉ d·ªÖ debug xem con n√†o ƒëang ch·∫°y
            print(f"   [GPU {gpu_id}] ƒê√£ xong: {processed_count}/{total_files} ·∫£nh", end="\r")

    print(f"‚úÖ [GPU {gpu_id}] HO√ÄN T·∫§T.")


# ================= S·ª¨A B∆Ø·ªöC 1: QU·∫¢N L√ù ƒêA GPU =================
def step1_multi_gpu_ocr():
    # --- PH·∫¶N M·ªöI: WARM-UP MODEL ---
    # M·ª•c ƒë√≠ch: T·∫£i model v·ªÅ cache 1 l·∫ßn duy nh·∫•t tr∆∞·ªõc khi chia process
    # ƒë·ªÉ tr√°nh 4 worker c√πng tranh nhau t·∫£i file g√¢y crash/hang.
    print("üîπ Pre-check: ƒêang ki·ªÉm tra/t·∫£i model PaddleOCR (Warm-up)...")
    try:
        from paddleocr import PaddleOCR
        # Ch·∫°y th·ª≠ init 1 l·∫ßn tr√™n CPU ƒë·ªÉ ƒë·∫£m b·∫£o file model ƒë√£ c√≥
        PaddleOCR(lang='german', use_angle_cls=False)
        print("‚úÖ Model check OK.")
    except Exception as e:
        print(f"‚ö†Ô∏è Warning Warm-up: {e}")
    # -------------------------------

    print(f"\nüîπ B∆Ø·ªöC 1: SCAN OCR V·ªöI {NUM_GPUS} GPU...")
    
    # ... (Ph·∫ßn qu√©t file gi·ªØ nguy√™n nh∆∞ c≈©) ...
    all_tasks = []
    for root, dirs, files in os.walk(RAW_DIR):
        rel_subdir = os.path.relpath(root, RAW_DIR)
        if rel_subdir == ".": rel_subdir = ""
        os.makedirs(os.path.join(JSON_DIR, rel_subdir), exist_ok=True)

        for f in files:
            if f.lower().endswith((".jpg", ".png", ".jpeg")):
                json_path = os.path.join(JSON_DIR, rel_subdir, f.replace(".jpg", ".json").replace(".png", ".json"))
                if not os.path.exists(json_path):
                    all_tasks.append((os.path.join(root, f), json_path, f))

    total_images = len(all_tasks)
    if total_images == 0:
        print("‚úÖ T·∫•t c·∫£ ·∫£nh ƒë√£ ƒë∆∞·ª£c OCR tr∆∞·ªõc ƒë√≥.")
        return

    print(f"üì¶ T·ªïng s·ªë ·∫£nh c·∫ßn x·ª≠ l√Ω: {total_images}")
    
    # S·∫Øp x·∫øp task ng·∫´u nhi√™n ƒë·ªÉ tr√°nh vi·ªác 1 GPU nh·∫≠n to√†n ·∫£nh n·∫∑ng, 1 GPU to√†n ·∫£nh nh·∫π
    import random
    random.shuffle(all_tasks)

    # Chia ƒë·ªÅu c√¥ng vi·ªác
    chunk_size = math.ceil(total_images / NUM_GPUS)
    chunks = [all_tasks[i:i + chunk_size] for i in range(0, total_images, chunk_size)]

    processes = []
    start_time = time.time()
    
    for i in range(len(chunks)):
        if not chunks[i]: continue
        real_gpu_id = i % NUM_GPUS 
        p = Process(target=worker_ocr_process, args=(real_gpu_id, chunks[i]))
        p.start()
        processes.append(p)

    for p in processes:
        p.join()

    end_time = time.time()
    print(f"\n‚úÖ Ho√†n t·∫•t OCR trong {end_time - start_time:.2f} gi√¢y.")

# ================= C√ÅC B∆Ø·ªöC C√íN L·∫†I (GI·ªÆ NGUY√äN) =================
def step2_translate_batch():
    print("\nüîπ B∆Ø·ªöC 2: D·ªäCH THU·∫¨T...")
    all_jsons = glob.glob(f"{JSON_DIR}/**/*.json", recursive=True)
    
    need_trans = set()
    for js in all_jsons:
        with open(js, 'r', encoding='utf-8') as f:
            try: data = json.load(f)
            except: continue
            for item in data.get('texts', []):
                if not item.get('translated'):
                    txt = item['text'].strip()
                    if len(txt) > 1 and not txt.isdigit():
                        need_trans.add(txt)
    
    text_list = list(need_trans)
    if not text_list:
        print("‚úÖ T·∫•t c·∫£ ƒë√£ ƒë∆∞·ª£c d·ªãch.")
        return

    print(f"   ‚òÅÔ∏è  D·ªãch {len(text_list)} c·ª•m t·ª´...")
    trans_map = {}
    
    for i in range(0, len(text_list), BATCH_SIZE_TRANS):
        batch = text_list[i:i+BATCH_SIZE_TRANS]
        try:
            res = translator.translate_batch(batch)
            for s, d in zip(batch, res): trans_map[s] = d
        except:
            pass

    cnt = 0
    for js in all_jsons:
        with open(js, 'r', encoding='utf-8') as f:
            try: data = json.load(f)
            except: continue
        
        dirty = False
        for item in data.get('texts', []):
            orig = item['text'].strip()
            if not item.get('translated') and orig in trans_map:
                item['translated'] = trans_map[orig]
                dirty = True
        
        if dirty:
            with open(js, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            cnt += 1
    print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t {cnt} file JSON.")

def step3_render_images():
    print("\nüîπ B∆Ø·ªöC 3: V·∫º ·∫¢NH K·∫æT QU·∫¢...")
    for root, dirs, files in os.walk(RAW_DIR):
        rel_subdir = os.path.relpath(root, RAW_DIR)
        if rel_subdir == ".": rel_subdir = ""
        out_subdir = os.path.join(TRANSLATED_DIR, rel_subdir)
        json_subdir = os.path.join(JSON_DIR, rel_subdir)
        os.makedirs(out_subdir, exist_ok=True)

        for file in files:
            if not file.lower().endswith((".jpg", ".png")): continue
            img_path = os.path.join(root, file)
            json_path = os.path.join(json_subdir, file.replace(".jpg", ".json").replace(".png", ".json"))
            out_path = os.path.join(out_subdir, file)

            if not os.path.exists(json_path): continue
            
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            img_pil = Image.open(img_path).convert("RGB")
            draw = ImageDraw.Draw(img_pil)

            for item in data.get('texts', []):
                text_content = item.get('translated') if item.get('translated') else item['text']
                x1, y1, x2, y2 = item['box']
                render_text_in_box(draw, text_content, FONT_PATH, x1, y1, x2, y2)

            img_pil.save(out_path)
            print(f"Rendered: {file}", end='\r')

    print("\n‚úÖ Ho√†n t·∫•t to√†n b·ªô quy tr√¨nh!")

def main():
    # Set start method th√†nh spawn ƒë·ªÉ an to√†n v·ªõi CUDA
    try:
        set_start_method('spawn')
    except RuntimeError:
        pass
        
    step1_multi_gpu_ocr()
    step2_translate_batch()
    step3_render_images()

if __name__ == "__main__":
    main()